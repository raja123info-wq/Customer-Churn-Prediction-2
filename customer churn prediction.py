# -*- coding: utf-8 -*-
"""Untitled22.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10YtCrJgoA9RXuiXa1JqQrg3LPdXy6dWu
"""

# Customer Churn — EDA, Preprocessing, Logistic Regression (with CV & interpretation)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,
    confusion_matrix, classification_report, roc_curve, precision_recall_curve, auc
)
from sklearn.impute import SimpleImputer
import pickle
import os

# ---------- CONFIG ----------
DATA_PATH = r"C:\Users\darkr\Documents\course project\dataset\Telco-Customer-Churn.csv"
MODEL_PATH = "churn_model.pkl"
RANDOM_STATE = 42
TEST_SIZE = 0.20
CV_FOLDS = 5
# ----------------------------

# 1) LOAD
try:
    df = pd.read_csv(DATA_PATH)
    print("✅ Loaded dataset shape:", df.shape)
    display(df.head())
except FileNotFoundError:
    print(f"❌ Error: File not found at {DATA_PATH}")
    print("Please check the file path and ensure the CSV exists.")
    raise

# 2) QUICK OVERVIEW
print("\n--- Info & Nulls ---")
print(df.info())
print("\nMissing values per column:\n", df.isnull().sum())

# Some Telco datasets have 'TotalCharges' as object with spaces -> convert
if 'TotalCharges' in df.columns:
    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
    print("\nTotalCharges after conversion - nulls:", df['TotalCharges'].isnull().sum())
    if df['TotalCharges'].isnull().sum() > 0:
        df = df.dropna(subset=['TotalCharges']).reset_index(drop=True)
        print("Dropped rows with missing TotalCharges. New shape:", df.shape)

# 3) Basic cleaning
# Drop customerID if present
if 'customerID' in df.columns:
    df = df.drop(columns=['customerID'])

# Map target
if 'Churn' in df.columns:
    df['Churn'] = df['Churn'].map({'Yes':1, 'No':0})
    print("Churn value counts:\n", df['Churn'].value_counts())

# 4) EDA — distributions & relationships
# Separate numerical and categorical
num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
num_cols = [c for c in num_cols if c != 'Churn']  # exclude target
cat_cols = df.select_dtypes(include=['object']).columns.tolist()

print("\nNumerical cols:", num_cols)
print("Categorical cols:", cat_cols)

# Univariate numeric distributions
plt.figure(figsize=(14,4))
for i, col in enumerate(num_cols):
    plt.subplot(1, len(num_cols), i+1)
    sns.histplot(df[col], kde=True)
    plt.title(col)
plt.tight_layout()
plt.show()

# Target vs numerical boxplots / violin to see relationship
for col in num_cols:
    plt.figure(figsize=(6,3))
    sns.boxplot(x='Churn', y=col, data=df)
    plt.title(f"{col} by Churn")
    plt.show()

# Categorical distributions (bar) and churn rate by category
for col in cat_cols:
    counts = df[col].value_counts()
    if len(counts) > 20:
        top = counts.nlargest(10)
        print(f"\n{col} (top 10 counts):\n", top)
    else:
        plt.figure(figsize=(8,3))
        sns.countplot(data=df, x=col, order=df[col].value_counts().index)
        plt.xticks(rotation=45)
        plt.title(f"Counts for {col}")
        plt.show()

    churn_pct = df.groupby(col)['Churn'].mean().sort_values(ascending=False)
    display(churn_pct.to_frame(name='churn_rate').head(10))

# Correlation heatmap for numeric variables (including target)
plt.figure(figsize=(6,5))
sns.heatmap(df[num_cols + ['Churn']].corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Numeric Correlations (incl. Churn)")
plt.show()

# Categorical features correlation with churn
overall_churn = df['Churn'].mean()
cat_churn_impacts = []
for col in cat_cols:
    rates = df.groupby(col)['Churn'].mean()
    spread = rates.max() - rates.min()
    cat_churn_impacts.append((col, spread))
cat_churn_impacts = sorted(cat_churn_impacts, key=lambda x: x[1], reverse=True)
print("Categorical features sorted by churn-rate spread (top 10):")
for col, spread in cat_churn_impacts[:10]:
    print(f"{col}: spread = {spread:.3f}")

# 5) PREPROCESSING
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(transformers=[
    ('num', numeric_transformer, num_cols),
    ('cat', categorical_transformer, cat_cols)
], remainder='drop')

# 6) TRAIN-TEST SPLIT
X = df.drop(columns=['Churn'])
y = df['Churn']
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y
)
print("\nTrain shape:", X_train.shape, "Test shape:", X_test.shape)
print("Train churn rate:", y_train.mean(), "Test churn rate:", y_test.mean())

# 7) PIPELINE with Logistic Regression and CV
pipe = Pipeline(steps=[
    ('preproc', preprocessor),
    ('clf', LogisticRegression(solver='liblinear', max_iter=1000, class_weight='balanced', random_state=RANDOM_STATE))
])

param_grid = {
    'clf__C': [0.01, 0.1, 1.0, 5.0, 10.0],
    'clf__penalty': ['l1', 'l2']
}

cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)
grid = GridSearchCV(pipe, param_grid, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=1)
grid.fit(X_train, y_train)

print("\n✅ Best params:", grid.best_params_)
print("✅ Best CV ROC AUC:", grid.best_score_)

best_model = grid.best_estimator_

# 8) EVALUATE on test set
y_pred = best_model.predict(X_test)
y_prob = best_model.predict_proba(X_test)[:,1]

acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred, zero_division=0)
rec = recall_score(y_test, y_pred, zero_division=0)
f1 = f1_score(y_test, y_pred, zero_division=0)
roc = roc_auc_score(y_test, y_prob)

print("\n--- Test set performance ---")
print(f"Accuracy:  {acc:.4f}")
print(f"Precision: {prec:.4f}")
print(f"Recall:    {rec:.4f}")
print(f"F1-score:  {f1:.4f}")
print(f"ROC AUC:   {roc:.4f}")

print("\nClassification Report:\n")
print(classification_report(y_test, y_pred, digits=4))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(4,3))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0,1], yticklabels=[0,1])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
plt.figure(figsize=(6,4))
plt.plot(fpr, tpr, label=f'ROC AUC = {roc:.3f}')
plt.plot([0,1],[0,1],'--', alpha=0.6)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

# Precision-Recall curve
precision_vals, recall_vals, pr_thresholds = precision_recall_curve(y_test, y_prob)
pr_auc = auc(recall_vals, precision_vals)
plt.figure(figsize=(6,4))
plt.plot(recall_vals, precision_vals, label=f'PR AUC = {pr_auc:.3f}')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend()
plt.show()

# 9) FEATURE IMPORTANCE: map coefficients back to feature names
ohe = best_model.named_steps['preproc'].named_transformers_['cat'].named_steps['onehot']
num_after = num_cols

# Build feature names list
cat_feature_names = []
if hasattr(ohe, 'get_feature_names_out'):
    cat_feature_names = ohe.get_feature_names_out(cat_cols)
else:
    for i, col in enumerate(cat_cols):
        cats = best_model.named_steps['preproc'].named_transformers_['cat'].named_steps['onehot'].categories_[i][1:]
        cat_feature_names += [f"{col}_{c}" for c in cats]

feature_names = list(cat_feature_names) + list(num_after)

coefs = best_model.named_steps['clf'].coef_[0]
coef_df = pd.DataFrame({'feature': feature_names, 'coef': coefs})
coef_df['abs_coef'] = coef_df['coef'].abs()
coef_df = coef_df.sort_values(by='abs_coef', ascending=False).reset_index(drop=True)
display(coef_df.head(20))

print("\nTop features increasing churn (positive coefficients):")
display(coef_df[coef_df['coef']>0].head(10))

print("\nTop features decreasing churn (negative coefficients):")
display(coef_df[coef_df['coef']<0].head(10))

print("\nInterpretation guidance:")
print("- Positive coefficient = increases churn probability")
print("- Negative coefficient = decreases churn probability")

# 10) THRESHOLD EXPLORATION
thresholds = np.linspace(0.01, 0.99, 99)
metrics = []
for th in thresholds:
    y_th = (y_prob >= th).astype(int)
    metrics.append({
        'threshold': th,
        'precision': precision_score(y_test, y_th, zero_division=0),
        'recall': recall_score(y_test, y_th, zero_division=0),
        'f1': f1_score(y_test, y_th, zero_division=0)
    })
metrics_df = pd.DataFrame(metrics)
plt.figure(figsize=(8,4))
plt.plot(metrics_df['threshold'], metrics_df['precision'], label='Precision')
plt.plot(metrics_df['threshold'], metrics_df['recall'], label='Recall')
plt.plot(metrics_df['threshold'], metrics_df['f1'], label='F1')
plt.xlabel('Threshold')
plt.ylabel('Score')
plt.title('Precision / Recall / F1 vs threshold')
plt.legend()
plt.show()

# 11) SAVE MODEL
try:
    with open(MODEL_PATH, 'wb') as f:
        pickle.dump(best_model, f, protocol=pickle.HIGHEST_PROTOCOL)
    print(f"\n✅ Model saved successfully to '{MODEL_PATH}'")
except Exception as e:
    print(f"❌ Error saving model: {str(e)}")

print("\n✅ Done. Script completed.")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

# 1. Load Data
df = pd.read_csv(r"C:\Users\darkr\Documents\course project\dataset\Telco-Customer-Churn.csv")

# Drop ID column (if exists)
if "customerID" in df.columns:
    df = df.drop("customerID", axis=1)

# Convert TotalCharges (if needed)
if "TotalCharges" in df.columns:
    df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")

# Fill missing values for numeric columns
# For simplicity, using mean imputation for numeric columns only
for col in df.select_dtypes(include=np.number).columns:
    if df[col].isnull().any():
        df[col] = df[col].fillna(df[col].mean())

# Convert 'Churn' target variable to numerical (0 and 1) BEFORE one-hot encoding
df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})

# Separate Features (X) and Target (y) BEFORE one-hot encoding features
X = df.drop("Churn", axis=1)
y = df["Churn"]

# One-hot encode categorical columns in X
X = pd.get_dummies(X, drop_first=True)

# 2. Train-Test Split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)

# 3. Scale numerical features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. Build and Train Logistic Regression Model
model = LogisticRegression(max_iter=1000, class_weight="balanced")
model.fit(X_train_scaled, y_train)

# 5. Make Predictions
y_pred = model.predict(X_test_scaled)

# 6. Evaluate Model
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.2f}")

# 7. Predict for a NEW CUSTOMER (Sample Input)
# Ensure the new customer DataFrame has the same columns and order as X after one-hot encoding
new_customer = pd.DataFrame([X.iloc[0]], columns=X.columns)

# Scale the new customer data
new_customer_scaled = scaler.transform(new_customer)

# Predict churn
predicted_class = model.predict(new_customer_scaled)[0]
predicted_probability = model.predict_proba(new_customer_scaled)[0][1]

# Print Results
print(f"Predicted Churn Class: {predicted_class}")
print(f"Churn Probability: {predicted_probability:.2f}")

